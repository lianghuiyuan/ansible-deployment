---
# https://github.com/apache/kafka/blob/3.7/docker/examples/jvm/cluster/combined/plaintext/docker-compose.yml
# https://github.com/apache/kafka/blob/3.7/docker/examples/README.md
# https://github.com/apache/kafka/blob/3.7/config/kraft/server.properties
# https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md
# https://kafka.apache.org/documentation/#configuration


- name: Set quorum voters for each Kafka broker
  set_fact:
    kafka_controller_quorum_voters: "{{ kafka_controller_quorum_voters | default([]) + [hostvars[item]['kafka_broker_id'] ~ '@' ~ hostvars[item]['host_inner_address'] ~ ':' ~ hostvars[item]['kafka_host_controller_port']] }}"
  with_items: "{{ groups['docker_kafka'] }}"
  tags: ['always']

- name: container | Ensure directorys has correct ownership
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    owner: '1000'
    group: '1000'
    mode: '0777'
    recurse: yes
  with_items: 
    - '{{ kafka_home_dir }}'
  tags: ['install', 'start', 'recreate', 'update']

- name: container | {{ docker_container_state }} kafka container
  community.docker.docker_container:
    name: 'kafka_{{ kafka_broker_id }}'
    image: '{{ kafka_image }}:{{ kafka_version }}'
    hostname: 'kafka_{{ kafka_broker_id }}'
    state: '{{ docker_container_state }}'        # choices: [absent, present, healthy, stopped, started]
    restart: '{{ docker_container_restart }}'    # Use with started state to force a matching container to be stopped and restarted.
    recreate: '{{ docker_container_recreate }}'  # Use with present and started states to force the re-creation of an existing container.
    restart_policy: always
    ports:
      - "{{ kafka_host_broker_port }}:9092"
      - "{{ kafka_host_controller_port }}:9093"
    volumes:
      - '{{ kafka_home_dir }}:/bitnami/kafka'
    env:
      KAFKA_KRAFT_CLUSTER_ID: '{{ kafka_cluster_id }}'
      KAFKA_CFG_NODE_ID: '{{ kafka_broker_id | string }}'
      KAFKA_CFG_PROCESS_ROLES: 'broker,controller'
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "{{ kafka_controller_quorum_voters | join(',') }}"
      KAFKA_CFG_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093'
      KAFKA_CFG_ADVERTISED_LISTENERS: 'PLAINTEXT://{{ kafka_service_ip }}:{{ kafka_host_broker_port }}'
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: '3'
      KAFKA_CFG_REPLICATION_FACTOR: '3'
      KAFKA_CFG_DEFAULT_REPLICATION_FACTOR: '3'
      KAFKA_CFG_GROUP_INITIAL_REBALANCE_DELAY_MS: '0'
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: '3'
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: '3'
      KAFKA_CFG_NUM_NETWORK_THREADS: '9'       # 一般设置: CPU 核数 + 1
      KAFKA_CFG_NUM_IO_THREADS: '16'            # 一般设置: CPU 核数 * 2，最大不超过 CPU 核数 * 3
      # KAFKA_CFG_HEAP_OPTS: '-Xms2g -Xmx2g'
      KAFKA_CFG_NUM_PARTITIONS: '13'
      # KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'false' 
      KAFKA_CFG_LOG_CLEANUP_POLICY: 'delete'        # The default cleanup policy for segments beyond the retention window
      KAFKA_CFG_LOG_RETENTION_MS: '604800000'        # 7 days   删除前的缓冲时间。the maximum time we will retain a log before we will discard old log segments to free up space if we are using the "delete" retention policy.
      KAFKA_CFG_LOG_RETENTION_BYTES: '10737418240'    # 10 GB
      KAFKA_CFG_LOG_SEGMENT_MS: '604800000'          # 7 days
      KAFKA_CFG_LOG_SEGMENT_BYTES: '1073741824'      # 1GiB
      KAFKA_CFG_LOG4J_LOGGER_KAFKA: 'WARN'           # DEBUG、INFO、WARN、ERROR
      KAFKA_CFG_LOG4J_ROOTLOGGER: 'WARN, stdout'
      KAFKA_CFG_LOG4J_LOGGERS: 'WARN'
  tags: ['install', 'start', 'stop', 'restart', 'uninstall','destory', 'recreate', 'update']

- name: remove directorys
  ansible.builtin.file:
    path: "{{ item }}"
    state: absent
  with_items: 
    - '{{ kafka_home_dir }}'
  tags: ['destory']